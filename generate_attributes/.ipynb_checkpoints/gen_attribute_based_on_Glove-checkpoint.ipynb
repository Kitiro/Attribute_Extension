{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzc/anaconda3/envs/exp/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 111] Connection refused>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import os \n",
    "from datetime import datetime\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# model = KeyedVectors.load_word2vec_format('pretrained_model/wiki-news-300d-1M.vec', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzc/anaconda3/envs/exp/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# load glove \n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    " \n",
    "# 输入文件\n",
    "glove_file = 'pretrained_model/glove.6B.300d.txt'\n",
    " \n",
    "# 输出文件\n",
    "tmp_file = \"pretrained_model/glove_word2vec_300d.txt\"\n",
    " \n",
    "# 转换成word2vec的词向量\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    " \n",
    "# 加载转化后的文件\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file, binary=False)\n",
    " \n",
    "import _pickle \n",
    "# 序列化\n",
    "with open('pretrained_model/pickled_model_300d', 'wb') as f:\n",
    "    _pickle.dump(model, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761861\n"
     ]
    }
   ],
   "source": [
    "import _pickle \n",
    "# 测试模型\n",
    "f = open('pretrained_model/pickled_model_300d', 'rb')\n",
    "model = _pickle.load(f)\n",
    "print(model.similarity('have','has'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vec(vecs):\n",
    "    total = np.array([0.0]*300)\n",
    "    for v in vecs:\n",
    "        total += v\n",
    "    return total/len(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antelope', 'grizzly+bear', 'killer+whale', 'beaver', 'dalmatian', 'persian+cat', 'horse', 'german+shepherd', 'blue+whale', 'siamese+cat', 'skunk', 'mole', 'tiger', 'hippopotamus', 'leopard', 'moose', 'spider+monkey', 'humpback+whale', 'elephant', 'gorilla', 'ox', 'fox', 'sheep', 'seal', 'chimpanzee', 'hamster', 'squirrel', 'rhinoceros', 'rabbit', 'bat', 'giraffe', 'wolf', 'chihuahua', 'rat', 'weasel', 'otter', 'buffalo', 'zebra', 'giant+panda', 'deer', 'bobcat', 'pig', 'lion', 'mouse', 'polar+bear', 'collie', 'walrus', 'raccoon', 'cow', 'dolphin']\n",
      "antelope 1\n",
      "(300,)\n",
      "grizzly+bear 2\n",
      "(300,)\n",
      "killer+whale 2\n",
      "(300,)\n",
      "beaver 1\n",
      "(300,)\n",
      "dalmatian 1\n",
      "(300,)\n",
      "persian+cat 2\n",
      "(300,)\n",
      "horse 1\n",
      "(300,)\n",
      "german+shepherd 2\n",
      "(300,)\n",
      "blue+whale 2\n",
      "(300,)\n",
      "siamese+cat 2\n",
      "(300,)\n",
      "skunk 1\n",
      "(300,)\n",
      "mole 1\n",
      "(300,)\n",
      "tiger 1\n",
      "(300,)\n",
      "hippopotamus 1\n",
      "(300,)\n",
      "leopard 1\n",
      "(300,)\n",
      "moose 1\n",
      "(300,)\n",
      "spider+monkey 2\n",
      "(300,)\n",
      "humpback+whale 2\n",
      "(300,)\n",
      "elephant 1\n",
      "(300,)\n",
      "gorilla 1\n",
      "(300,)\n",
      "ox 1\n",
      "(300,)\n",
      "fox 1\n",
      "(300,)\n",
      "sheep 1\n",
      "(300,)\n",
      "seal 1\n",
      "(300,)\n",
      "chimpanzee 1\n",
      "(300,)\n",
      "hamster 1\n",
      "(300,)\n",
      "squirrel 1\n",
      "(300,)\n",
      "rhinoceros 1\n",
      "(300,)\n",
      "rabbit 1\n",
      "(300,)\n",
      "bat 1\n",
      "(300,)\n",
      "giraffe 1\n",
      "(300,)\n",
      "wolf 1\n",
      "(300,)\n",
      "chihuahua 1\n",
      "(300,)\n",
      "rat 1\n",
      "(300,)\n",
      "weasel 1\n",
      "(300,)\n",
      "otter 1\n",
      "(300,)\n",
      "buffalo 1\n",
      "(300,)\n",
      "zebra 1\n",
      "(300,)\n",
      "giant+panda 2\n",
      "(300,)\n",
      "deer 1\n",
      "(300,)\n",
      "bobcat 1\n",
      "(300,)\n",
      "pig 1\n",
      "(300,)\n",
      "lion 1\n",
      "(300,)\n",
      "mouse 1\n",
      "(300,)\n",
      "polar+bear 2\n",
      "(300,)\n",
      "collie 1\n",
      "(300,)\n",
      "walrus 1\n",
      "(300,)\n",
      "raccoon 1\n",
      "(300,)\n",
      "cow 1\n",
      "(300,)\n",
      "dolphin 1\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "# 为AWA2的类产生vector\n",
    "awa2_class = []\n",
    "#读取动物列表\n",
    "with open('data/awa_class.txt') as f:\n",
    "    lines=f.readlines()\n",
    "    for i in lines:\n",
    "        awa2_class.append(i.strip())\n",
    "\n",
    "vec_dict = {}\n",
    "print(awa2_class)\n",
    "\n",
    "for i in awa2_class:\n",
    "    vecs = []\n",
    "    for j in i.split('+'):\n",
    "        try:\n",
    "            vecs.append(model[j])\n",
    "        except:\n",
    "            print('lost', j, '-', i)\n",
    "    print(i, len(vecs))\n",
    "    vec_dict[i] = mean_vec(vecs)\n",
    "    print(vec_dict[i].shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t\t\t    generated_attributes\r\n",
      "gen_attribute_based_on_BERT.ipynb   generated_attributes_glove\r\n",
      "gen_attribute_based_on_Glove.ipynb  pretrained_model\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black_footed_albatross', 'laysan_albatross', 'sooty_albatross', 'groove_billed_ani', 'crested_auklet', 'least_auklet', 'parakeet_auklet', 'rhinoceros_auklet', 'brewer_blackbird', 'red_winged_blackbird', 'rusty_blackbird', 'yellow_headed_blackbird', 'bobolink', 'indigo_bunting', 'lazuli_bunting', 'painted_bunting', 'cardinal', 'spotted_catbird', 'gray_catbird', 'yellow_breasted_chat', 'eastern_towhee', 'chuck_will_widow', 'brandt_cormorant', 'red_faced_cormorant', 'pelagic_cormorant', 'bronzed_cowbird', 'shiny_cowbird', 'brown_creeper', 'american_crow', 'fish_crow', 'black_billed_cuckoo', 'mangrove_cuckoo', 'yellow_billed_cuckoo', 'gray_crowned_rosy_finch', 'purple_finch', 'northern_flicker', 'acadian_flycatcher', 'great_crested_flycatcher', 'least_flycatcher', 'olive_sided_flycatcher', 'scissor_tailed_flycatcher', 'vermilion_flycatcher', 'yellow_bellied_flycatcher', 'frigatebird', 'northern_fulmar', 'gadwall', 'american_goldfinch', 'european_goldfinch', 'boat_tailed_grackle', 'eared_grebe', 'horned_grebe', 'pied_billed_grebe', 'western_grebe', 'blue_grosbeak', 'evening_grosbeak', 'pine_grosbeak', 'rose_breasted_grosbeak', 'pigeon_guillemot', 'california_gull', 'glaucous_winged_gull', 'heermann_gull', 'herring_gull', 'ivory_gull', 'ring_billed_gull', 'slaty_backed_gull', 'western_gull', 'anna_hummingbird', 'ruby_throated_hummingbird', 'rufous_hummingbird', 'green_violetear', 'long_tailed_jaeger', 'pomarine_jaeger', 'blue_jay', 'florida_jay', 'green_jay', 'dark_eyed_junco', 'tropical_kingbird', 'gray_kingbird', 'belted_kingfisher', 'green_kingfisher', 'pied_kingfisher', 'ringed_kingfisher', 'white_breasted_kingfisher', 'red_legged_kittiwake', 'horned_lark', 'pacific_loon', 'mallard', 'western_meadowlark', 'hooded_merganser', 'red_breasted_merganser', 'mockingbird', 'nighthawk', 'clark_nutcracker', 'white_breasted_nuthatch', 'baltimore_oriole', 'hooded_oriole', 'orchard_oriole', 'scott_oriole', 'ovenbird', 'brown_pelican', 'white_pelican', 'western_wood_pewee', 'sayornis', 'american_pipit', 'whip_poor_will', 'horned_puffin', 'common_raven', 'white_necked_raven', 'american_redstart', 'geococcyx', 'loggerhead_shrike', 'great_grey_shrike', 'baird_sparrow', 'black_throated_sparrow', 'brewer_sparrow', 'chipping_sparrow', 'clay_colored_sparrow', 'house_sparrow', 'field_sparrow', 'fox_sparrow', 'grasshopper_sparrow', 'harris_sparrow', 'henslow_sparrow', 'le_conte_sparrow', 'lincoln_sparrow', 'nelson_sharp_tailed_sparrow', 'savannah_sparrow', 'seaside_sparrow', 'song_sparrow', 'tree_sparrow', 'vesper_sparrow', 'white_crowned_sparrow', 'white_throated_sparrow', 'cape_glossy_starling', 'bank_swallow', 'barn_swallow', 'cliff_swallow', 'tree_swallow', 'scarlet_tanager', 'summer_tanager', 'artic_tern', 'black_tern', 'caspian_tern', 'common_tern', 'elegant_tern', 'forsters_tern', 'least_tern', 'green_tailed_towhee', 'brown_thrasher', 'sage_thrasher', 'black_capped_vireo', 'blue_headed_vireo', 'philadelphia_vireo', 'red_eyed_vireo', 'warbling_vireo', 'white_eyed_vireo', 'yellow_throated_vireo', 'bay_breasted_warbler', 'black_and_white_warbler', 'black_throated_blue_warbler', 'blue_winged_warbler', 'canada_warbler', 'cape_may_warbler', 'cerulean_warbler', 'chestnut_sided_warbler', 'golden_winged_warbler', 'hooded_warbler', 'kentucky_warbler', 'magnolia_warbler', 'mourning_warbler', 'myrtle_warbler', 'nashville_warbler', 'orange_crowned_warbler', 'palm_warbler', 'pine_warbler', 'prairie_warbler', 'prothonotary_warbler', 'swainson_warbler', 'tennessee_warbler', 'wilson_warbler', 'worm_eating_warbler', 'yellow_warbler', 'northern_waterthrush', 'louisiana_waterthrush', 'bohemian_waxwing', 'cedar_waxwing', 'american_three_toed_woodpecker', 'pileated_woodpecker', 'red_bellied_woodpecker', 'red_cockaded_woodpecker', 'red_headed_woodpecker', 'downy_woodpecker', 'bewick_wren', 'cactus_wren', 'carolina_wren', 'house_wren', 'marsh_wren', 'rock_wren', 'winter_wren', 'common_yellowthroat']\n",
      "lost violetear - green_violetear\n",
      "lost pomarine - pomarine_jaeger\n",
      "lost sayornis - sayornis\n",
      "lost geococcyx - geococcyx\n",
      "lost forsters - forsters_tern\n",
      "lost waterthrush - northern_waterthrush\n",
      "lost waterthrush - louisiana_waterthrush\n"
     ]
    }
   ],
   "source": [
    "cub_class = []\n",
    "with open('data/cub_class.txt') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        name = line.strip().lower()\n",
    "        cub_class.append(name)\n",
    "print(cub_class)\n",
    "\n",
    "vec_dict = {}\n",
    "\n",
    "for i in cub_class:\n",
    "    vecs = []\n",
    "    for j in i.split('_'):\n",
    "        try:\n",
    "            vecs.append(model[j])\n",
    "        except:\n",
    "            print('lost', j, '-', i)\n",
    "    if len(vecs) == 0:\n",
    "        vec_dict[i] = np.array([0]*300)\n",
    "    else:\n",
    "        vec_dict[i] = mean_vec(vecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bakery_shop', 'bar', 'barn', 'airlock', 'boathouse', 'bookstore', 'bridge', 'butchers_shop', 'candy_store', 'carrousel', 'temple_south_asia', 'castle', 'cliff', 'closet', 'coast', 'dam', 'dock', 'fastfood_restaurant', 'fly_bridge', 'fountain', 'home_theater', 'house', 'lift_bridge', 'monastery_outdoor', 'piano_store', 'lighthouse', 'manufactured_home', 'mobile_home', 'nursery', 'palace', 'patio', 'pier', 'watering_hole', 'restaurant', 'restaurant_patio', 'roof', 'rope_bridge', 'sandbar', 'geodesic_dome_indoor', 'sawmill', 'sea_cliff', 'seawall', 'roundabout', 'toyshop', 'trestle_bridge', 'underwater_coral_reef', 'underwater_wreck', 'valley', 'viaduct', 'volcano', 'water_tower', 'vegetable_garden', 'chemical_plant', 'chemistry_lab', 'residential_neighborhood', 'tent_indoor', 'utility_room', 'vineyard', 'swimming_hole', 'darkroom', 'shipping_room', 'shed', 'gangplank', 'forest_broadleaf', 'ferryboat_outdoor', 'campus', 'railroad_track', 'auto_racing_paddock', 'zoo', 'garage_outdoor', 'strip_mine', 'fish_farm', 'brewery_indoor', 'airfield', 'pub_indoor', 'vestry', 'glacier', 'dolmen', 'bistro_outdoor', 'music_store', 'diner_outdoor', 'general_store_outdoor', 'bullpen', 'barndoor', 'discotheque', 'bog', 'poolroom_home', 'warehouse_indoor', 'art_studio', 'thriftshop', 'campsite', 'golf_course', 'jail_indoor', 'train_railway', 'carport_outdoor', 'wrestling_ring_indoor', 'atrium_public', 'museum_outdoor', 'woodland', 'trading_floor']\n",
      "lost barndoor - barndoor\n",
      "lost thriftshop - thriftshop\n",
      "lost videostore - videostore\n",
      "lost needleleaf - forest_needleleaf\n",
      "lost oilrig - oilrig\n",
      "lost kindergarden - kindergarden_classroom\n",
      "lost frontseat - car_interior_frontseat\n",
      "lost procenium - theater_indoor_procenium\n"
     ]
    }
   ],
   "source": [
    "# 为SUN数据集的类别产生特征文件\n",
    "from scipy import io as sio\n",
    "import numpy as np\n",
    "dataset = 'SUN_data'\n",
    "image_embedding = 'res101'\n",
    "class_embedding = 'att' # original_att\n",
    "\n",
    "path = '../data/SUN_data/'\n",
    "\n",
    "matcontent = sio.loadmat(path+'res101.mat')\n",
    "\n",
    "label = matcontent['labels'].astype(int).squeeze() - 1\n",
    "\n",
    "matcontent = sio.loadmat(path+'att_splits.mat')\n",
    "trainval_loc = matcontent['trainval_loc'].squeeze() - 1\n",
    "train_label = np.unique(label[trainval_loc].astype(int))  # 645 \n",
    "\n",
    "test_unseen_loc = matcontent['test_unseen_loc'].squeeze() - 1\n",
    "test_label = np.unique(label[test_unseen_loc].astype(int)) # 72 class\n",
    "\n",
    "with open(path +'trainvalclasses.txt') as f:\n",
    "    lines=f.readlines()\n",
    "    train_class = [i.strip() for i in lines]\n",
    "with open(path +'testclasses.txt') as f:\n",
    "    lines=f.readlines()\n",
    "    test_class = [i.strip() for i in lines]\n",
    "sun_class = []\n",
    "train_index = 0\n",
    "test_index = 0\n",
    "for i in range(717):\n",
    "    if i in train_label:\n",
    "        sun_class.append(train_class[train_index])\n",
    "        train_index += 1\n",
    "    else:\n",
    "        sun_class.append(test_class[test_index])\n",
    "        test_index += 1\n",
    "print(sun_class[:100])\n",
    "vec_dict = {}\n",
    "\n",
    "for i in sun_class:\n",
    "    vecs = []\n",
    "    for j in i.split('_'):\n",
    "        try:\n",
    "            vecs.append(model[j])\n",
    "        except:\n",
    "            print('lost', j, '-', i)\n",
    "    if len(vecs) == 0:\n",
    "        vec_dict[i] = np.array([0]*300)\n",
    "    else:\n",
    "        vec_dict[i] = mean_vec(vecs)\n",
    "        \n",
    "vec_dict['barndoor'] = mean_vec([model['barn'], model['door']])\n",
    "vec_dict['videostore'] = mean_vec([model['video'], model['store']])\n",
    "vec_dict['oilrig'] = mean_vec([model['oil']])\n",
    "vec_dict['thriftshop'] = mean_vec([model['thrift'], model['shop']])\n",
    "vec_dict['theater_indoor_procenium'] = mean_vec([model['theater'], model['indoor'], model['proscenium']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8 10 11 17 21 23 25 26 27 29 30 31]\n",
      "[ 9 12 13 14 15 16 18 19 20 22 24 28]\n",
      "[]\n",
      "lost tvmonitor - tvmonitor\n",
      "lost pottedplant - pottedplant\n",
      "lost diningtable - diningtable\n"
     ]
    }
   ],
   "source": [
    "# 为APY数据集的类别产生特征文件\n",
    "from scipy import io as sio\n",
    "import numpy as np\n",
    "dataset = 'APY_data/'\n",
    "\n",
    "path = '../data/'+dataset\n",
    "\n",
    "matcontent = sio.loadmat(path+'res101.mat')\n",
    "\n",
    "label = matcontent['labels'].astype(int).squeeze() - 1\n",
    "\n",
    "matcontent = sio.loadmat(path+'att_splits.mat')\n",
    "trainval_loc = matcontent['trainval_loc'].squeeze() - 1\n",
    "train_label = np.unique(label[trainval_loc].astype(int))  # 645 \n",
    "\n",
    "print(train_label)\n",
    "test_unseen_loc = matcontent['test_unseen_loc'].squeeze() - 1\n",
    "test_label = np.unique(label[test_unseen_loc].astype(int)) # 72 class\n",
    "print(test_label)\n",
    "\n",
    "with open(path +'trainvalclasses.txt') as f:\n",
    "    lines=f.readlines()\n",
    "    train_class = [i.strip() for i in lines]\n",
    "with open(path +'testclasses.txt') as f:\n",
    "    lines=f.readlines()\n",
    "    test_class = [i.strip() for i in lines]\n",
    "apy_class = []\n",
    "print(apy_class[:100])\n",
    "train_index = 0\n",
    "test_index = 0\n",
    "for i in range(32):\n",
    "    if i in train_label:\n",
    "        apy_class.append(train_class[train_index])\n",
    "        train_index += 1\n",
    "    else:\n",
    "        apy_class.append(test_class[test_index])\n",
    "        test_index += 1\n",
    "\n",
    "vec_dict = {}\n",
    "\n",
    "for i in apy_class:\n",
    "    vecs = []\n",
    "    for j in i.split('_'):\n",
    "        try:\n",
    "            vecs.append(model[j])\n",
    "        except:\n",
    "            print('lost', j, '-', i)\n",
    "    if len(vecs) == 0:\n",
    "        vec_dict[i] = np.array([0]*300)\n",
    "    else:\n",
    "        vec_dict[i] = mean_vec(vecs)\n",
    "        \n",
    "vec_dict['tvmonitor'] = mean_vec([model['tv'], model['monitor']])\n",
    "vec_dict['pottedplant'] = mean_vec([model['potted'], model['plant']])\n",
    "vec_dict['diningtable '] = mean_vec([model['dining'], model['table']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['single-engined', 'ultra-light', 'dirigible', 'twin-engined', 'piston-engined', 'aerobatic', 'ultralight', 'all-metal', 'sergeant-major', 'piston-powered', 'three-engined', 'air-cooled', 'aeronautical', 'gasoline-powered', 'locomotive', 'radar-equipped', 'four-engined', 'unpowered', 'turbojet-powered', 'radio-controlled', 'u-3', 'rocket-powered', 'supersonic', '0-4-0', 'mass-produced', 'propeller-driven', 'carrier-based', 'jet-powered', 'australian-built', 'underpowered', 'amateur-built', 'solar-powered', 'german-based', 'remote-controlled', 'anglo-egyptian', 'license-built', 'multi-engined', 'full-scale', 'all-british', 'open-top', 'turbine-powered', 'switzerland-based', 'electric-powered', 'anti-ukrainian', '2-2-2', 'three-wheeled', 'old-style', '4-4-0', 'american-built', 'french-built']\n",
      "word num(after filtering non-adj word) 3659\n",
      "total class num: 32\n",
      "3 class are incompleted\n",
      "['tvmonitor', 'pottedplant', 'diningtable']\n"
     ]
    }
   ],
   "source": [
    "# 有w2v的API产生最相似的词\n",
    "import nltk \n",
    "# 需要指定此处的class_list\n",
    "class_list = apy_class\n",
    "\n",
    "all_attr = []\n",
    "lost = []\n",
    "top_k = 2000\n",
    "dict_name = {}\n",
    "\n",
    "adj = ['JJ','JJR','JJS']\n",
    "    \n",
    "    \n",
    "#把所有生成属性存成一维数组\n",
    "for i in class_list:\n",
    "    for j in i.split('_'):\n",
    "        try:\n",
    "            class_attr = model.most_similar(j, topn=top_k)\n",
    "            class_attr = [ j[0] for j in class_attr]  #只取name 舍弃相似度\n",
    "            all_attr.extend(class_attr)\n",
    "        except:\n",
    "            lost.append(j)\n",
    "        \n",
    "#把得到的所有属性中不属于adj的筛选掉\n",
    "result_adj = [nltk.pos_tag([word])[0][0] for word in all_attr if nltk.pos_tag([word])[0][1] in adj]\n",
    "print(result_adj[:50])\n",
    "print('word num(after filtering non-adj word)',len(result_adj))\n",
    "\n",
    "classes = [j for j in class_list if j not in lost]\n",
    "print('total class num:',len(class_list))\n",
    "print(len(lost),'class are incompleted')\n",
    "print(lost[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#按词频排序\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "num_wanted = 300 #想要的属性数量, awa2-50, cub-312, sun-102, apy-64\n",
    "\n",
    "counter = Counter(result_adj)\n",
    "attr_selected = [attr[0] for attr in counter.most_common(num_wanted)]\n",
    "\n",
    "# 通过cosine相似度为类与生成的属性进行赋值\n",
    "attr_vec_dict = {}\n",
    "for attr in attr_selected:\n",
    "    attr_vec = model[attr]\n",
    "    attr_vec_dict[attr] = attr_vec\n",
    "    \n",
    "attribute_matrix = []\n",
    "for i in class_list: \n",
    "    class_vec = vec_dict[i]\n",
    "    attr_sim = []\n",
    "    for attr in attr_selected:\n",
    "        attr_vec = attr_vec_dict[attr]\n",
    "        sim = cosine_similarity([class_vec,attr_vec])\n",
    "        attr_sim.append(sim[0][1])\n",
    "\n",
    "    attribute_matrix.append(attr_sim)\n",
    "attribute_matrix = np.array(attribute_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['small',\n",
       " 'little',\n",
       " 'same',\n",
       " 'own',\n",
       " 'red',\n",
       " 'big',\n",
       " 'similar',\n",
       " 'dead',\n",
       " 'tiny',\n",
       " 'few',\n",
       " 'large',\n",
       " 'single',\n",
       " 'full',\n",
       " 'old',\n",
       " 'black',\n",
       " 'green',\n",
       " 'next',\n",
       " 'white',\n",
       " 'flat',\n",
       " 'easy',\n",
       " 'empty',\n",
       " 'famous',\n",
       " 'safe',\n",
       " 'great',\n",
       " 'whole',\n",
       " 'golden',\n",
       " 'last',\n",
       " 'other',\n",
       " 'feral',\n",
       " 'good',\n",
       " 'ready',\n",
       " 'many',\n",
       " 'puppy',\n",
       " 'anthropomorphic',\n",
       " 'naked',\n",
       " 'electric',\n",
       " 'local',\n",
       " 'several',\n",
       " 'typical',\n",
       " 'most',\n",
       " 'resemble',\n",
       " 'hot',\n",
       " 'second',\n",
       " 'able',\n",
       " 'lucky',\n",
       " 'nice',\n",
       " 'loose',\n",
       " 'bad',\n",
       " 'locomotive',\n",
       " 'armored',\n",
       " 'modern',\n",
       " 'collapsible',\n",
       " 'geese',\n",
       " 'common',\n",
       " 'white-tailed',\n",
       " 'live',\n",
       " 'suspicious',\n",
       " 'different',\n",
       " 'available',\n",
       " 'happy',\n",
       " 'third',\n",
       " 'much',\n",
       " 'alive',\n",
       " 'hard',\n",
       " 'special',\n",
       " 'pedestrian',\n",
       " 'thoroughbred',\n",
       " 'popular',\n",
       " 'short',\n",
       " 'nest',\n",
       " 'veterinarian',\n",
       " 'mythical',\n",
       " 'mysterious',\n",
       " 'such',\n",
       " 'particular',\n",
       " 'least',\n",
       " 'huge',\n",
       " 'best',\n",
       " 'larger',\n",
       " 'occasional',\n",
       " 'new',\n",
       " 'bigger',\n",
       " 'northern',\n",
       " 'young',\n",
       " 'private',\n",
       " 'entire',\n",
       " 'unicorn',\n",
       " 'stationary',\n",
       " 'busy',\n",
       " 'upright',\n",
       " 'mechanical',\n",
       " 'regular',\n",
       " 'inflatable',\n",
       " 'unusual',\n",
       " 'exotic',\n",
       " 'affected',\n",
       " 'possible',\n",
       " 'true',\n",
       " 'healthy',\n",
       " 'likely',\n",
       " 'smaller',\n",
       " 'fourth',\n",
       " 'injured',\n",
       " 'civilian',\n",
       " 'open',\n",
       " 'soft',\n",
       " 'extra',\n",
       " 'wrong',\n",
       " 'older',\n",
       " 'real',\n",
       " 'original',\n",
       " 'comic',\n",
       " 'short-tailed',\n",
       " 'traditional',\n",
       " 'open-top',\n",
       " 'electrical',\n",
       " 'disabled',\n",
       " 'automatic',\n",
       " 'successful',\n",
       " 'expensive',\n",
       " 'explosive',\n",
       " 'fresh',\n",
       " 'southern',\n",
       " 'domestic',\n",
       " 'curious',\n",
       " 'eastern',\n",
       " 'oldest',\n",
       " 'largest',\n",
       " 'massive',\n",
       " 'dangerous',\n",
       " 'serious',\n",
       " '40-foot',\n",
       " 'heavy',\n",
       " 'commercial',\n",
       " 'unidentified',\n",
       " 'british',\n",
       " 'gigantic',\n",
       " 'luxurious',\n",
       " 'ceramic',\n",
       " 'separate',\n",
       " 'main',\n",
       " 'actual',\n",
       " 'adorable',\n",
       " 'stupid',\n",
       " 'dalmatian',\n",
       " 'arabian',\n",
       " 'floppy',\n",
       " 'legendary',\n",
       " 'friesian',\n",
       " 'three-wheeled',\n",
       " 'aerial',\n",
       " 'two-wheeled',\n",
       " 'accessible',\n",
       " 'improvised',\n",
       " 'portable',\n",
       " 'grand',\n",
       " 'free',\n",
       " 'international',\n",
       " 'national',\n",
       " '45-minute',\n",
       " 'unlocked',\n",
       " 'veterinary',\n",
       " 'related',\n",
       " 'natural',\n",
       " 'important',\n",
       " 'latest',\n",
       " 'recent',\n",
       " 'sensitive',\n",
       " 'western',\n",
       " 'siberian',\n",
       " 'certain',\n",
       " 'familiar',\n",
       " 'greatest',\n",
       " 'unknown',\n",
       " 'arctic',\n",
       " '60-foot',\n",
       " '24-foot',\n",
       " '22-foot',\n",
       " '28-foot',\n",
       " 'clear',\n",
       " 'unable',\n",
       " 'attic',\n",
       " '10-pound',\n",
       " '202-547-4512',\n",
       " 'palestinian',\n",
       " 'funeral',\n",
       " 'major',\n",
       " 'due',\n",
       " 'responsible',\n",
       " 'easier',\n",
       " 'mischievous',\n",
       " '3-year',\n",
       " '2-year',\n",
       " 'one-eyed',\n",
       " 'gorgeous',\n",
       " 'asiatic',\n",
       " 'comfortable',\n",
       " 'cathedral',\n",
       " 'victorian',\n",
       " 'vegetarian',\n",
       " 'ritual',\n",
       " 'sacrificial',\n",
       " 'additional',\n",
       " 'suitable',\n",
       " 'unpowered',\n",
       " 'supersonic',\n",
       " 'six-wheeled',\n",
       " 'non-stop',\n",
       " 'steam-powered',\n",
       " 'eight-legged',\n",
       " 'pneumatic',\n",
       " 'amphibious',\n",
       " 'single-handed',\n",
       " 'unmanned',\n",
       " 'amphibian',\n",
       " 'recreational',\n",
       " 'fixed-gear',\n",
       " 'equestrian',\n",
       " 'professional',\n",
       " 'casual',\n",
       " 'automotive',\n",
       " 'inexpensive',\n",
       " 'postal',\n",
       " 'fastest',\n",
       " 'nationwide',\n",
       " '4-wheel',\n",
       " 'italian',\n",
       " 'daily',\n",
       " 'conventional',\n",
       " 'athletic',\n",
       " 'reusable',\n",
       " 'urban',\n",
       " 'rear-mounted',\n",
       " 'various',\n",
       " 'chic',\n",
       " 'competitive',\n",
       " 'avian',\n",
       " 'contagious',\n",
       " 'aquatic',\n",
       " 'isolated',\n",
       " 'nocturnal',\n",
       " 'probable',\n",
       " 'native',\n",
       " 'edible',\n",
       " 'genetic',\n",
       " 'worst',\n",
       " 'chinese',\n",
       " 'positive',\n",
       " 'eurasian',\n",
       " 'pelican',\n",
       " 'severe',\n",
       " 'european',\n",
       " 'susceptible',\n",
       " 'southeastern',\n",
       " 'regional',\n",
       " 'illegal',\n",
       " 'individual',\n",
       " 'biggest',\n",
       " 'difficult',\n",
       " 'low',\n",
       " 'interested',\n",
       " 'arrive',\n",
       " '30-foot',\n",
       " '12-meter',\n",
       " '20-foot',\n",
       " '17-foot',\n",
       " '16-foot',\n",
       " 'japanese',\n",
       " 'unloaded',\n",
       " '12-foot',\n",
       " '14-foot',\n",
       " '25-foot',\n",
       " 'temporary',\n",
       " 'northeastern',\n",
       " 'upturned',\n",
       " '35-foot',\n",
       " 'australian',\n",
       " 'pouch',\n",
       " 'alcoholic',\n",
       " 'bubble',\n",
       " 'olive',\n",
       " 'underwear',\n",
       " 'magical',\n",
       " '10-cent',\n",
       " 'central',\n",
       " 'israeli',\n",
       " 'residential',\n",
       " 'direct',\n",
       " 'limited',\n",
       " 'normal',\n",
       " '18-wheeler',\n",
       " 'serial',\n",
       " 'convertible',\n",
       " 'previous',\n",
       " 'german',\n",
       " 'personal',\n",
       " 'american',\n",
       " 'overall',\n",
       " 'quiet',\n",
       " 'continued']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 300)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "attribute_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribute_matrix = np.array(attribute_matrix)\n",
    "#np.save('/home/zzc/exp/zsl/generate_attributes/generated_attributes/class_attribute_map_cub_'+str(num_wanted)+'.npy',attribute_matrix)\n",
    "np.save('generated_attributes_glove/class_attribute_map_APY.npy',attribute_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
